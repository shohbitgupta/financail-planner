# Financial Plan Evaluator Agent

## Overview

The Financial Plan Evaluator Agent is an advanced quality control system that uses **Gemini 2.5 Pro** to evaluate and improve financial planning responses generated by **Llama 3.2**. This creates a two-tier AI system where Gemini acts as a senior financial expert reviewing and enhancing the initial recommendations.

## Architecture

```
User Request â†’ Llama 3.2 (Initial Response) â†’ Gemini 2.5 Pro (Evaluation & Improvement) â†’ Enhanced Response
```

### Key Components

1. **Primary LLM**: Llama 3.2 (Local via Ollama)
   - Generates initial financial planning responses
   - Fast, local processing
   - Good baseline financial advice

2. **Evaluator LLM**: Gemini 2.5 Pro (Google AI)
   - Evaluates response quality on 6 criteria
   - Generates improved responses when needed
   - Acts as senior financial expert reviewer

## Evaluation Criteria

The evaluator scores responses on a 1-10 scale across 6 weighted criteria:

| Criteria | Weight | Description |
|----------|--------|-------------|
| **Accuracy** | 25% | Financial calculations and realistic return expectations |
| **Completeness** | 20% | All required sections present and well-developed |
| **Specificity** | 20% | Specific instruments (Tesla, Apple) vs generic advice |
| **Risk Alignment** | 15% | Recommendations match user's risk tolerance |
| **Market Relevance** | 10% | UAE/US market opportunities properly addressed |
| **Compliance** | 10% | Sharia compliance if required |

**Overall Score Calculation**: Weighted average of all criteria scores

## How It Works

### 1. Initial Response Generation
```python
# Llama 3.2 generates initial financial plan
llm_response = ollama_model.invoke(user_prompt)
```

### 2. Quality Evaluation
```python
# Gemini 2.5 Pro evaluates the response
evaluation_results = evaluator.evaluate_response_quality(
    llm_response, user_data, financial_metrics
)
```

### 3. Improvement Decision
- **Score â‰¥ 8.0**: Response is excellent, no improvement needed
- **Score < 8.0**: Generate improved response using Gemini

### 4. Response Enhancement
```python
# Gemini generates improved response based on evaluation feedback
improved_response = evaluator.generate_improved_response(
    original_response, user_data, financial_metrics, evaluation_results
)
```

## Setup Instructions

### 1. Install Dependencies
```bash
cd flask_api
pip install google-generativeai==0.8.3
```

### 2. Get Gemini API Key
1. Visit: https://aistudio.google.com/app/apikey
2. Create a new API key
3. Copy the API key

### 3. Configure Environment
```bash
# Option 1: Run setup script
python setup_evaluator.py

# Option 2: Manual setup
echo "GEMINI_API_KEY=your_api_key_here" > .env
```

### 4. Restart Flask API
```bash
python standalone_app.py
```

## API Integration

The evaluator is automatically integrated into the existing `/api/generate-financial-plan` endpoint:

```python
@app.route('/api/generate-financial-plan', methods=['POST'])
def generate_financial_plan():
    # 1. Generate initial response with Llama 3.2
    llm_response = ollama_model.invoke(prompt)
    
    # 2. Evaluate and improve with Gemini 2.5 Pro
    if EVALUATOR_AVAILABLE:
        evaluation_results, improved_response = evaluate_and_improve_response(
            llm_response, user_data, financial_metrics
        )
        llm_response = improved_response
    
    # 3. Return enhanced response
    return structured_plan
```

## Response Metadata

Each API response now includes evaluation metadata:

```json
{
  "user_profile": {...},
  "recommendations": [...],
  "evaluation_metadata": {
    "evaluator_used": true,
    "original_score": 7.2,
    "improvement_applied": true,
    "evaluation_timestamp": "2025-01-27T10:30:00"
  }
}
```

## Benefits

### 1. **Quality Assurance**
- Automatic quality scoring on 6 financial planning criteria
- Consistent evaluation standards
- Objective improvement recommendations

### 2. **Enhanced Specificity**
- Pushes for specific instrument recommendations (Tesla, Apple, Emirates NBD)
- Reduces generic advice
- Improves actionability

### 3. **Risk Alignment**
- Ensures recommendations match user risk tolerance
- Validates portfolio construction logic
- Checks market-specific advice

### 4. **Compliance Verification**
- Validates Sharia compliance when required
- Checks regulatory considerations
- Ensures appropriate disclaimers

## Example Evaluation Flow

### Input (User Profile)
```json
{
  "age": 30,
  "retirement_age": 60,
  "annual_salary": 100000,
  "risk_tolerance": "aggressive",
  "preferred_market": "US"
}
```

### Llama 3.2 Initial Response
```
PORTFOLIO RECOMMENDATIONS:
- Stocks: 70% allocation
- Bonds: 20% allocation  
- Cash: 10% allocation
```

### Gemini Evaluation
```json
{
  "specificity_score": 4,
  "specificity_feedback": "Recommendations are too generic. Should specify actual stocks like Tesla, Apple, Microsoft instead of just 'Stocks'",
  "overall_score": 6.8
}
```

### Gemini Improved Response
```
PORTFOLIO RECOMMENDATIONS:
- Tesla (TSLA): 15% allocation - High growth potential in EV market
- Apple (AAPL): 20% allocation - Stable tech giant with strong fundamentals
- Microsoft (MSFT): 15% allocation - Cloud computing leader
- SPDR S&P 500 ETF (SPY): 20% allocation - Broad market exposure
- US Treasury Bonds: 20% allocation - Risk mitigation
- Cash: 10% allocation - Emergency fund and opportunities
```

## Error Handling

The system gracefully handles various failure scenarios:

1. **Gemini API Unavailable**: Falls back to Llama 3.2 only
2. **API Key Missing**: Logs warning, continues without evaluation
3. **Evaluation Errors**: Uses original response, logs error details
4. **Network Issues**: Timeout handling with fallback

## Performance Considerations

- **Latency**: Adds ~2-3 seconds for evaluation and improvement
- **Cost**: Gemini API calls only when improvement needed (score < 8.0)
- **Reliability**: Fallback to original response if evaluator fails
- **Caching**: Future enhancement to cache evaluations for similar profiles

## Monitoring

The system provides detailed logging:

```
âœ… Evaluator agent loaded successfully
ðŸ§ª Evaluating response with Gemini 2.5 Pro...
ðŸ“Š Response quality score: 6.8. Generating improved response...
âœ… Using improved response from evaluator agent
```

## Future Enhancements

1. **Custom Evaluation Criteria**: User-specific evaluation weights
2. **Multi-Model Evaluation**: Compare multiple LLM responses
3. **Learning System**: Improve evaluation based on user feedback
4. **Performance Analytics**: Track improvement metrics over time
